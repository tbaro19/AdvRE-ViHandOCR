# ğŸ§¨ Adversarial_Attack_OCR

This repository demonstrates adversarial attacks on an OCR model using **Projected Gradient Descent (PGD)**. The goal is to evaluate and reduce the robustness of OCR systems by generating adversarial perturbations using three different strategies:

- **Global PGD**
- **HF-Focused PGD**
- **Stroke-Focused PGD**

## ğŸ“ Repository Structure

Adversarial_Attack_OCR/
â”œâ”€â”€ data/Train/ # Training dataset (images + labels)
â”œâ”€â”€ train_vietocr.py # Script to train the VietOCR model
â”œâ”€â”€ attack_PGD.py # PGD attack script for Global and HF-Focused variants
â”œâ”€â”€ Stroke_focused.py # PGD attack script for Stroke-Focused variant
â”œâ”€â”€ README.md # Project documentation


## ğŸ§ª Attack Variants

### 1. Global PGD

- Implemented in: `attack_PGD.py`
- Perturbs the **entire image uniformly**
- Serves as the **baseline** PGD attack

### 2. HF-Focused PGD

- Also in: `attack_PGD.py`
- Perturbs only **high-frequency regions** such as edges and textures
- Requires setting `"hf_focus"` inside the script

### 3. Stroke-Focused PGD

- Implemented in: `Stroke_focused.py`
- Perturbs only the **character stroke regions**
- Designed for more **localized and stealthy** adversarial perturbations

> ğŸ” To switch between Global and HF-Focused PGD, edit the `attack_mode` variable inside `attack_PGD.py`.

ğŸš€ Usage Instructions
1. Install Dependencies
pip install torch torchvision vietocr opencv-python numpy

2. Train the OCR Model
python train_vietocr.py
You may need to modify data paths inside the script depending on your setup.

3. Run Global or HF-Focused PGD Attack
python attack_PGD.py
Make sure to set the desired attack_mode inside the script ("global" or "hf_focus")

4. Run Stroke-Focused PGD Attack
python Stroke_focused.py

âš™ï¸ Attack Parameters
Each PGD attack can be configured with the following hyperparameters:

epsilon: Maximum perturbation magnitude (Lâˆ norm)

steps: Number of PGD iterations

step-size: Step size for each PGD step

You can either pass these via CLI (if implemented) or modify directly inside the script.

ğŸ“Š (Optional) Evaluation Metrics
If you wish to evaluate the impact of attacks on model performance:

Character Error Rate (CER)

Word Error Rate (WER)

Sequence error rate (SER)

These can be computed by comparing predictions on clean vs. adversarial images.

ğŸ“Œ Notes
All attacks are white-box, using gradients from the trained OCR model.

The OCR model is based on VietOCR.

Dataset used: Vietnamese printed or handwritten text samples under data/Train/.

ğŸ‘¤ Author
tbaro19
